---
title: "STAA 567 Assignment 4"
author: "Jon Dollard"
date: "11/15/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(gridExtra) #gives you grid.arrange()
library(knitr)     #making tables
```

1. In a few words (not mathematical equations), answer the following questions.

(a) What is the goal of the EM algorithm?

The goal of the EM algorithm is to find the MLE of a probability density function.

(b) We are covering EM as an optimization method.  What function is optimized in the EM algorithm?

The EM algorithm is used to optimize (find the maximum) of the function $Q(\theta|\theta^{(t)})$ = E{$logL(\theta|Y)|x, \theta^{(t)}$}

2. Mixture distributions:  Consider the following distributions:

(1)  $f(x) = \pi_1f_1(x)\ + \pi_2f_2(x) \ + \pi_3f(x), where \sum_{i=1}^3 \pi_i = 1$

(a) Simulate 1000 observations from equation (1) when $\pi_1 = \pi_2 = \pi_3 = 1/3$ and $f_1, f_2, f_3$ are given by N(2,2), N(12,2), and N(22,2), respectively.

Draw a histogram of your simulated data (y-axis is the count in each bin).

```{r, message=FALSE}
#Define equations and parameters
set.seed(567)
n <- 1000

f_1 <- rnorm(n,2, 2)
f_2 <- rnorm(n,12, 2)
f_3 <- rnorm(n,22, 2)

m <- sample(c(0,1,2), size = n, replace = TRUE, prob = c((1/3), (1/3), (1/3)))

mix <- f_1
mix[m == 1] <- f_2[m == 1]
mix[m == 2] <- f_3[m == 2]

qplot(mix, geom = "histogram", main = "Histogram of 3 Normal Distributions", 
      xlab = "Data", ylab = "Count", fill = I("lightblue"), col = I("orange"), 
      alpha = I(.5)) 
  
```

(b) Redraw your histogram using the density scale on the y-axis.  Superimpose a smoothed density on your plot.

```{r, message=FALSE, warning=FALSE}
mix = as.data.frame(mix)
ggplot(mix, aes(x = mix)) +
 geom_histogram(aes(y = ..density..), color = "black", fill = "white", bins = 50) + 
  geom_density(alpha = 0.2, fill = "orange") +
  xlim(c(-10,35)) 
  
```

(c) Repeat question 2 (b) for $\pi_1 = 5/8, \pi_2 = 2/8, \pi_3 = 1/8$.  Use the same $f_1, f_2, f_3$ as 2 (a).

```{r, message=FALSE, warning=FALSE}
m <- sample(c(0,1,2), size = n, replace = TRUE, prob = c((5/8), (2/8), (1/8)))

mix <- f_1
mix[m == 1] <- f_2[m == 1]
mix[m == 2] <- f_3[m == 2]

mix = as.data.frame(mix)
ggplot(mix, aes(x = mix)) +
 geom_histogram(aes(y = ..density..), color = "black", fill = "white") + 
  geom_density(alpha = 0.2, fill = "red") +
  xlim(c(-10,35))
```

(d) Repeat 2(a) for n = 10, 20, 50, 100, and 1000 observations.  What happens the shape of the histogram as the sample size increases?  At what sample size do you think a statistical test could detect that a mixture distribution is an appropriate model for these data?

```{r, message=FALSE, include = FALSE}
n <- c(10, 20, 50, 100, 1000)

#Set a for loop to run all values of n
for(i in 1:length(n)){
  
  f_1 <- rnorm(n[i],2, 2)
  f_2 <- rnorm(n[i],12, 2)
  f_3 <- rnorm(n[i],22, 2)

  m <- sample(c(0,1,2), size = n[i], replace = TRUE, prob = c((1/3), (1/3), (1/3)))

  mix <- f_1
  mix[m == 1] <- f_2[m == 1]
  mix[m == 2] <- f_3[m == 2]

  plot <-qplot(mix, geom = "histogram", main = "Histogram of 3 Normal Distributions",
               xlab = "Data", ylab = "Count", fill = I("lightblue"), col = I("orange"),
               alpha = I(.5))
  
  print(plot)
}
```

As the sample size, n, increases we see that the histogram shape resolves into the mixture distributions.  This appears to happen somewhere between n = 50 and n = 100.  At n = 50 you can start to see the mixture distribution pattern emerging and it becomes visually clear at n = 100.

3. 

(a) Create your own 5-component mixture distribution.  Use something other than a normal distribution for your components.  Write out the equation for your 5-component mixture distribution.

My 5 component mixture distribution will be a mixture of 5 different beta distributions as follows:

$f(x) = \pi_1f_1(x)\ + \pi_2f_2(x) \ + \pi_3f(x) + \pi_4f_4(x) + \pi_5f_5(x), where \sum_{i=1}^5 \pi_i = 1$

and,

$f_1(x) = \beta(2,30)$, $f_2(x) = \beta(10,30)$, $f_3(x) = \beta(4, (30/30))$, $f_4(x) = \beta(30, 10)$, and $f_5(x) = \beta(30, 2)$ 

and,

$\pi_1 = \pi_2 = \pi_3 = \pi_4 = \pi_5 = \frac{1}{5}$

(b) Create a version of your 5-component mixture where the bumps are different sizes and so that you have 5 bumps in your histogram.  Simulate 10,000 observations from your distribution.  Create a histogram using the density scale on the y-axis.  Superimpose a smoothed density on your plot.  Turn in your plot and a brief description of the parameter values that you selected.

```{r, message=FALSE, warning=FALSE}
n <- 10000

f_1 <- rbeta(n,2,30)
f_2 <- rbeta(n,10,30)
f_3 <- rbeta(n,30,30)
f_4 <- rbeta(n,30,10)
f_5 <- rbeta(n,30,2)

m <- sample(c(0,1,2,3,4), size = n, replace = TRUE, prob = c(0.2, 0.35, 0.25, 0.15, 0.15))

mix <- f_1
mix[m == 1] <- f_2[m == 1]
mix[m == 2] <- f_3[m == 2]
mix[m == 3] <- f_4[m == 3]
mix[m == 4] <- f_5[m == 4]

mix = as.data.frame(mix)
ggplot(mix, aes(x = mix)) +
 geom_histogram(aes(y = ..density..), color = "black", fill = "white") + 
  geom_density(alpha = 0.2, fill = "orange")  +
  xlim(c(-.15,1.15))
```

I chose parameter values to create 5 Beta distributions that could be visually distinguished when mixed at the same proportion.  I like the symmetry created in this mixture distribution.

(c) For your 5-component mixture distribution repeat 3(a) for n = 10, 20, 50, 100, and 1000 observations.  What happens to the shape of the histogram as the sample size increases?  At what sample size do you think a statistical test could detect that a mixture distribution is an appropriate model for these data?  Is this the same sample size that you suggested for question 2(d)?

```{r, message=FALSE, include=FALSE}
n <- c(10, 20, 50, 100, 1000)

#Set a for loop to run all values of n
for(i in 1:length(n)){

  f_1 <- rbeta(n[i],2,30)
  f_2 <- rbeta(n[i],10,30)
  f_3 <- rbeta(n[i],30,30)
  f_4 <- rbeta(n[i],30,10)
  f_5 <- rbeta(n[i],30,2)

  m <- sample(c(0,1,2,3,4), size = n[i], replace = TRUE, prob = c(rep((1/5), 5)))

  mix <- f_1
  mix[m == 1] <- f_2[m == 1]
  mix[m == 2] <- f_3[m == 2]
  mix[m == 3] <- f_4[m == 3]
  mix[m == 4] <- f_5[m == 4]

  plot <-qplot(mix, geom = "histogram", main = "Histogram of 3 Normal Distributions",
               xlab = "Data", ylab = "Count", fill = I("lightblue"), col = I("orange"),
               alpha = I(.5))
  
    print(plot)
}
```

As the sample size, n, increases we see that the histogram shape resolves into the mixture distributions.  This appears to happen somewhere between n = 100 and n = 1000.  At n = 100 you can start to see some of the mixture distribution pattern emerging and it becomes visually clear at n = 1000.  Compared to 1(d) we need a larger sample size to begin to see the distribution develop.  This seems logical since we went from a mixture of 3 distributions to 5.





















































